{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.printing import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out, W = None, b = None, activation = T.tanh):\n",
    "        \"\"\"\n",
    "        HIdden layer of MAP\n",
    "        \n",
    "        rng: for random state --> np.random.RandomState\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        if W is None:\n",
    "            W_values = np.asarray(\n",
    "                rng.uniform(\n",
    "                    low = - np.sqrt(6. / (n_in + n_out)),\n",
    "                    high = np.sqrt(6. / (n_in + n_out)),\n",
    "                    size = (n_in, n_out)\n",
    "                    ),\n",
    "                dtype = theano.config.floatX\n",
    "                )\n",
    "            if activation == theano.tensor.nnet.sigmoid:\n",
    "                W_values *= 4.\n",
    "            \n",
    "            W1 = theano.shared(W_values, name='W1', borrow = True)\n",
    "        \n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b1 = theano.shared(value=b_values, name='b1', borrow=True)\n",
    "            \n",
    "        self.W = W1\n",
    "        self.b = b1\n",
    "            \n",
    "        lin_output = T.dot(input,self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if activation is None\n",
    "            else activation(lin_output)\n",
    "            )\n",
    "            \n",
    "        self.params = [self.W, self.b]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OutputLayer(object):\n",
    "    def __init__(self, rng, input, n_in, n_out, W = None, b = None, activation = None):\n",
    "        \"\"\"\n",
    "        Output layer of MAP\n",
    "        \n",
    "        rng: for random state --> np.random.RandomState\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        \n",
    "        if W is None:\n",
    "            W_values = np.asarray(\n",
    "                rng.uniform(\n",
    "                    low = - np.sqrt(6. / (n_in + n_out)),\n",
    "                    high = np.sqrt(6. / (n_in + n_out)),\n",
    "                    size = (n_in, n_out)\n",
    "                    ),\n",
    "                dtype = theano.config.floatX\n",
    "                )\n",
    "            if activation == theano.tensor.nnet.sigmoid:\n",
    "                W_values *= 4\n",
    "            \n",
    "            W2 = theano.shared(W_values, name='W2', borrow = True)\n",
    "            \n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype=theano.config.floatX)\n",
    "            b2 = theano.shared(value=b_values, name='b2', borrow=True)\n",
    "            \n",
    "        self.W = W2\n",
    "        self.b = b2\n",
    "            \n",
    "        lin_output = T.dot(input,self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if activation is None\n",
    "            else activation(lin_output)\n",
    "            )\n",
    "            \n",
    "        self.params = [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MAP(object):\n",
    "    \n",
    "    def __init__(self, rng, input, n_in, n_hidden, n_out):\n",
    "        \"\"\" Initialization\n",
    "        \"\"\"\n",
    "        self.hiddenLayer = HiddenLayer(\n",
    "            rng = rng,\n",
    "            input = input,\n",
    "            n_in = n_in,\n",
    "            n_out = n_hidden,\n",
    "            activation = T.tanh\n",
    "            )\n",
    "        \n",
    "        self.outputLayer = OutputLayer(\n",
    "            rng = rng,\n",
    "            input = self.hiddenLayer.output,\n",
    "            n_in = n_hidden,\n",
    "            n_out = n_out\n",
    "            )\n",
    "        \n",
    "        self.params = self.hiddenLayer.params + self.outputLayer.params\n",
    "        \n",
    "    def L2_regulation(self,y):\n",
    "        \"\"\" Returns the L2 regulation of object vector and predicted vetor\n",
    "        \"\"\"\n",
    "        \n",
    "        return T.sum((y - self.outputLayer.output) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MAPPING(object):\n",
    "    \"\"\" Returns the mapping function \n",
    "    X: np.array --> n_samples x n_features\n",
    "    Y: np.array --> n_samples x n_features\n",
    "    lam: penalization for weights\n",
    "    beta: weight for sparsity penalization\n",
    "    sparsity_param: desired average activation of the hidden units\n",
    "    \"\"\"\n",
    "    def __init__(self,learning_rate = 0.01, n_epochs = 1000, batch_size = 20, \n",
    "                 n_hidden = 200, lam = 1e-4, beta = 5, sparsity_param = 0.05):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lam = lam\n",
    "        self.beta = beta\n",
    "        self.sparsity_param = sparsity_param\n",
    "        self.W1  = None\n",
    "        self.W2 = None\n",
    "        self.b1 = None\n",
    "        self.b2 = None\n",
    "        self.x_mean = None\n",
    "        self.x_std = None\n",
    "        self.y_mean = None\n",
    "        self.y_std = None\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.x_mean = X.mean()\n",
    "        self.x_std = X.std()\n",
    "        self.y_mean = Y.mean()\n",
    "        self.y_std = Y.std()\n",
    "        X = (X - self.x_mean) / self.x_std\n",
    "        Y = (Y - self.y_mean) / self.y_std\n",
    "        n_batches = X.shape[0] / self.batch_size\n",
    "\n",
    "        shared_X = theano.shared(np.asarray(X, dtype = theano.config.floatX))\n",
    "        shared_Y = theano.shared(np.asarray(Y, dtype = theano.config.floatX))\n",
    "\n",
    "        ### Build model ###\n",
    "        print \"... building the model...\"\n",
    "\n",
    "        # allocate symbolic variables for the data\n",
    "        index = T.lscalar() # index for a mini batch\n",
    "        x = T.dmatrix('x')\n",
    "        y = T.dmatrix('y')\n",
    "\n",
    "        rng = np.random.RandomState(1234)\n",
    "\n",
    "        # construct MAP class\n",
    "        f_mapping = MAP(\n",
    "            rng = rng,\n",
    "            input = x,\n",
    "            n_in = X.shape[1],\n",
    "            n_hidden = self.n_hidden,\n",
    "            n_out = Y.shape[1]\n",
    "            )\n",
    "\n",
    "        ### Cost function ########################################################\n",
    "        hidden_output = f_mapping.hiddenLayer.output\n",
    "        rho_hat = (T.sum(hidden_output, axis = 0) / X.shape[0] + 1) / 2 ## rescale to [0,1]\n",
    "        L2 = f_mapping.L2_regulation(y)/ self.batch_size * 0.5 # penalization for vector\n",
    "        reg = 0.5 * self.lam * (T.sum(f_mapping.hiddenLayer.W ** 2) + T.sum(f_mapping.hiddenLayer.b **2) + T.sum(f_mapping.outputLayer.W ** 2) + T.sum(f_mapping.outputLayer.b ** 2))\n",
    "        sparsity = self.beta * T.sum(self.sparsity_param * T.log(self.sparsity_param / rho_hat) + (1 - self.sparsity_param) * T.log((1 - self.sparsity_param) / ( 1 - rho_hat)))\n",
    "        cost = L2 + sparsity + reg \n",
    "\n",
    "        # compute the gradient of the cost wrt to parameters\n",
    "        gparams = [T.grad(cost,param) for param in f_mapping.params]\n",
    "\n",
    "        # specify how to update parameters\n",
    "        updates = [\n",
    "            (param, param - self.learning_rate * gparam)\n",
    "            for param, gparam in zip(f_mapping.params, gparams)\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "        ## train the model\n",
    "        train_model = theano.function(\n",
    "            inputs = [index],\n",
    "            outputs = cost,\n",
    "            updates = updates,\n",
    "            givens={\n",
    "                x: shared_X[index * self.batch_size: (index + 1) * self.batch_size],\n",
    "                y: shared_Y[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "        start_time = time.clock()\n",
    "\n",
    "        epoch = 0\n",
    "        done_looping = False\n",
    "\n",
    "        while (epoch < self.n_epochs) and (not done_looping):\n",
    "            epoch += 1\n",
    "            for minibatch_index in xrange(n_batches):\n",
    "                minibatch_avg_cost = train_model(minibatch_index)\n",
    "        \n",
    "        self.W1 = f_mapping.hiddenLayer.W.get_value()\n",
    "        self.b1 = f_mapping.hiddenLayer.b.get_value()\n",
    "        self.W2 = f_mapping.outputLayer.W.get_value()\n",
    "        self.b2 = f_mapping.outputLayer.b.get_value()\n",
    "    \n",
    "    def transfrom(self,X):\n",
    "        \"\"\"\n",
    "        X: n_sample x n_features\n",
    "        \"\"\"\n",
    "        X = (X - self.x_mean)/self.x_std\n",
    "        Y = np.dot(np.tanh(np.dot(X,self.W1) + self.b1 ), self.W2 ) + self.b2\n",
    "        return Y * self.y_std + self.y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "f_dir = \"/home/ce/workspace/data-fusion/\"\n",
    "os.chdir(f_dir)\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 357 ms, total: 18.6 s\n",
      "Wall time: 18.6 s\n",
      "CPU times: user 406 ms, sys: 10.5 ms, total: 416 ms"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"data/cifar-10-batches-py/test_x\",\"r\") as f:\n",
    "    %time test_x = cPickle.load(f)\n",
    "with open(\"data/cifar-10-batches-py/test_y\",\"r\") as f:\n",
    "    %time test_y = cPickle.load(f)\n",
    "with open(\"data/cifar-10-batches-py/train_x\",\"r\") as f:\n",
    "    %time train_x = cPickle.load(f)\n",
    "with open(\"data/cifar-10-batches-py/train_y\",\"r\") as f:\n",
    "    %time train_y = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = MAPPING(n_hidden = 200, n_epochs = 200, batch_size = 200)\n",
    "%time mapping.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = mapping.transfrom(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y_pred = mapping.transfrom(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 ms, sys: 563 µs, total: 2.52 ms\n",
      "Wall time: 2.13 ms\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/cifar-10-batches-py/labels_vectors\",\"r\") as f:\n",
    "    %time label_vec = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim_cosine_train = np.zeros((train_y_pred.shape[0],label_vec.shape[0]))\n",
    "for i in xrange(train_y_pred.shape[0]):\n",
    "    for j in xrange(label_vec.shape[0]):\n",
    "        sim_cosine_train[i,j] = np.dot(train_y_pred[i],label_vec[j])/np.sqrt((train_y_pred[i]**2).sum())/np.sqrt((label_vec[j]**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_cosine = np.zeros((y_pred.shape[0],label_vec.shape[0]))\n",
    "for i in xrange(y_pred.shape[0]):\n",
    "    for j in xrange(label_vec.shape[0]):\n",
    "        sim_cosine[i,j] = np.dot(y_pred[i],label_vec[j])/np.sqrt((y_pred[i]**2).sum())/np.sqrt((label_vec[j]**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pred = np.argsort(sim_cosine)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## number of predict classes\n",
    "from collections import Counter\n",
    "print Counter(np.argsort(sim_cosine)[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "rank = 10 - np.where(np.argsort(sim_cosine) == 5)[1]\n",
    "pl.hist(rank,bins=10)\n",
    "pl.title('rank of dog label for dog images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "pl.hist(sim_cosine[np.where(np.argsort(sim_cosine) == 5)])\n",
    "pl.title('cosine similarity of dog label to predict label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_dog = np.zeros((train_x.shape[0] + test_x.shape[0],))\n",
    "tmp = np.concatenate((train_y_pred, y_pred))\n",
    "for i in xrange(cosine_dog.shape[0]):\n",
    "    cosine_dog[i] = np.dot(label_vec[5],tmp[i])/np.sqrt((label_vec[5]**2).sum())/np.sqrt((tmp[i]**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.argsort(cosine_dog)[::-1][:200]:\n",
    "    if i > train_x.shape[0] - 1:\n",
    "        print 'dog'\n",
    "    else:\n",
    "        j = int(labels[i])\n",
    "        print info[j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argsort(cosine_dog)[::-1][:100][0] > train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/home/ruoxu/workspace/data/cifar-10-batches-py/batches.meta\",\"r\") as f:\n",
    "    meta = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "info = []\n",
    "for i in meta[\"label_names\"]:\n",
    "    print j, i\n",
    "    info.append((j,i))\n",
    "    j+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.zeros((train_y.shape[0],))\n",
    "for i in xrange(train_y.shape[0]):\n",
    "    for j in xrange(label_vec.shape[0]):\n",
    "        if (label_vec[j] == train_y[i]).all():\n",
    "            labels[i] = j\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_cosine = np.zeros((train_y_pred.shape[0],label_vec.shape[0]))\n",
    "for i in xrange(train_y_pred.shape[0]):\n",
    "    for j in xrange(label_vec.shape[0]):\n",
    "        sim_cosine[i,j] = np.dot(train_y_pred[i],label_vec[j])/np.sqrt((train_y_pred[i]**2).sum())/np.sqrt((label_vec[j]**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print np.argsort(sim_cosine)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(np.array(np.argsort(sim_cosine)[:,-1]) == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
